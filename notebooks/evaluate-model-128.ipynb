{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c1cba5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import hickle as hkl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn_image as isns\n",
    "import rasterio as rs\n",
    "%run ../src/preprocessing/indices.py\n",
    "%run ../src/preprocessing/whittaker_smoother.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cbbd35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict_model_path = \"../models/75-composite-masterfeb9/\"\n",
    "predict_model_path = \"../models/tf2-nov6-44-master/\"\n",
    "#predict_model_path = \"../models/172-ttc-dec2023-3/\"\n",
    "#predict_model_path = \"../models/tf2-new/\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8cdd7c7-3092-47da-bfb2-b4e4789a236f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#!{sys.executable} -m pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8956bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from ../models/tf2-nov6-44-master/\n",
      "Metal device set to: Apple M3 Max\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-26 09:14:49.778339: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-02-26 09:14:49.778496: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "predict_graph_def = tf.compat.v1.GraphDef()\n",
    "if os.path.exists(predict_model_path):\n",
    "    print(f\"Loading model from {predict_model_path}\")\n",
    "    predict_file = tf.io.gfile.GFile(predict_model_path + \"predict_graph-76.pb\", 'rb')\n",
    "    predict_graph_def.ParseFromString(predict_file.read())\n",
    "    predict_graph = tf.import_graph_def(predict_graph_def, name='predict')\n",
    "    predict_sess = tf.compat.v1.Session(graph=predict_graph)\n",
    "    predict_logits = predict_sess.graph.get_tensor_by_name(f\"conv2d/Sigmoid:0\") \n",
    "    #predict_logits = predict_sess.graph.get_tensor_by_name(f\"predict/clip_by_value:0\") \n",
    "    #feature_extraction = predict_sess.graph.get_tensor_by_name(f\"predict/csse_out_mul/mul:0\")  \n",
    "    predict_inp = predict_sess.graph.get_tensor_by_name(\"Placeholder:0\")\n",
    "    predict_length = predict_sess.graph.get_tensor_by_name(\"PlaceholderWithDefault:0\")\n",
    "else:\n",
    "    raise Exception(f\"The model path {predict_model_path} does not exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6fa4abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 76\n",
    "min_all = [0.006576638437476157, 0.0162050812542916, 0.010040436408026246, \n",
    "               0.013351644159609368, 0.01965362020294499, 0.014229037918669413, \n",
    "               0.015289539940489814, 0.011993591210803388, 0.008239871824216068,\n",
    "               0.006546120393682765, 0.0, 0.0, 0.0, -0.1409399364817101,\n",
    "               -0.4973397113668104, -0.09731556326714398, -0.7193834232943873]\n",
    "\n",
    "max_all = [0.2691233691920348, 0.3740291447318227, 0.5171435111009385, \n",
    "           0.6027466239414053, 0.5650263218127718, 0.5747005416952773,\n",
    "           0.5933928435187305, 0.6034943160143434, 0.7472037842374304,\n",
    "           0.7000076295109483, \n",
    "           0.4,\n",
    "           0.948334642387533, \n",
    "           0.6729257769285485, 0.8177635298774327, 0.35768999002433816,\n",
    "           0.7545951919107605, 0.7602693339366691]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8d56681",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_to_db(x: np.ndarray, min_db: int) -> np.ndarray:\n",
    "    \"\"\" Converts unitless backscatter coefficient\n",
    "        to db with a min_db lower threshold\n",
    "        \n",
    "        Parameters:\n",
    "         x (np.ndarray): unitless backscatter (T, X, Y, B) array\n",
    "         min_db (int): integer from -50 to 0\n",
    "    \n",
    "        Returns:\n",
    "         x (np.ndarray): db backscatter (T, X, Y, B) array\n",
    "    \"\"\"\n",
    "    \n",
    "    x = 10 * np.log10(x + 1/65535)\n",
    "    x[x < -min_db] = -min_db\n",
    "    x = (x + min_db) / min_db\n",
    "    return np.clip(x, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05733b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "\n",
    "def preprocess_sample(sample, idx):\n",
    "\n",
    "    med = np.median(sample, axis = 0)\n",
    "    med = med[np.newaxis, :, :, :]\n",
    "   # sample = np.concatenate([sample, med], axis = 0)\n",
    "    \n",
    "    sample = np.core.umath.clip(sample, min_all, max_all)\n",
    "    sample = (sample - midrange) / (rng / 2)\n",
    "    \"\"\"\n",
    "    for band in range(0, sample.shape[-1]):\n",
    "        mins = min_all[band]\n",
    "        maxs = max_all[band]\n",
    "        sample[..., band] = np.clip(sample[..., band], mins, maxs)\n",
    "        midrange = (maxs + mins) / 2\n",
    "        rng = maxs - mins\n",
    "        standardized = (sample[..., band] - midrange) / (rng / 2)\n",
    "        sample[..., band] = standardized\n",
    "    \"\"\"\n",
    "    return sample\n",
    "\n",
    "\n",
    "def predict_subtile(subtile: np.ndarray, sess: \"tf.Sess\", op: \"tf.Tensor\", size: \"int\") -> np.ndarray:\n",
    "    \"\"\" Runs temporal (convGRU + UNET) predictions on a (12, 216, 216, 17) array:\n",
    "        - Calculates remote sensing indices\n",
    "        - Normalizes data\n",
    "        - Returns predictions for subtile\n",
    "\n",
    "        Parameters:\n",
    "         subtile (np.ndarray): monthly sentinel 2 + sentinel 1 mosaics\n",
    "         sess (tf.Session): tensorflow session for prediction\n",
    "    \n",
    "        Returns:\n",
    "         preds (np.ndarray): (160, 160) float32 [0, 1] predictions\n",
    "    \"\"\"\n",
    "    #np.save('subtile.npy', subtile)\n",
    "    if np.sum(subtile) != 0:\n",
    "        if not isinstance(subtile.flat[0], np.floating):\n",
    "            print(\"CONVERTING TO FLOAT\")\n",
    "            assert np.max(subtile) > 1\n",
    "            subtile = subtile / 65535.\n",
    "\n",
    "        time1 = time.time()\n",
    "        #subtile = np.core.umath.clip(subtile, min_all, max_all)\n",
    "        #subtile = (subtile - midrange) / (rng / 2)\n",
    "        batch_x = subtile[np.newaxis].astype(np.float32)\n",
    "        lengths = np.full((batch_x.shape[0]), args.length)\n",
    "        #print(\"length is \", LEN)\n",
    "        time2 = time.time()\n",
    "        \n",
    "        time1 = time.time()\n",
    "        #preds = sess.run(predict_earlyfeats,\n",
    "       #                       feed_dict={predict_inp:batch_x, \n",
    "        #                                 predict_length:lengths})\n",
    "        #batch_x = np.delete(batch_x, [11, 12], axis = -1)\n",
    "        preds = sess.run(op,\n",
    "                              feed_dict={predict_inp:batch_x, \n",
    "                                         predict_length:lengths})\n",
    "\n",
    "        #preds = sess.run(op,\n",
    "        #                      feed_dict={predict_inp:batch_x, \n",
    "        #                                 predict_length:lengths})\n",
    "\n",
    "\n",
    "        preds = preds.squeeze()\n",
    "\n",
    "        clip = (preds.shape[0] - size) // 2\n",
    "        #preds = preds[1:-1, 1:-1]\n",
    "        if clip > 0:\n",
    "            preds = preds[clip:-clip, clip:-clip]\n",
    "        #preds = np.clip(preds, 0, 1)\n",
    "        preds = np.float32(preds)\n",
    "        time2 = time.time()\n",
    "\n",
    "    else:\n",
    "        preds = np.full((SIZE, SIZE), 255)\n",
    "        print(f\"The sum of the subtile is {np.sum(subtile)}\")\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8111a65-480b-4e79-864f-8eaebd4bcdf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.load(\"../src/train-ard-y/20520248.npy\")\n",
    "np.max(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c5f2822",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = '/Volumes/John/train-ard-128/'\n",
    "ypath = '/Volumes/John/data/train-17k-may2023/train-y/'\n",
    "\n",
    "#fpath = '/Volumes/John/data/output-large-ard-x/'\n",
    "#ypath = '/Volumes/John/data/output-large-ard-y/'\n",
    "x_files = [x[:-4] for x in os.listdir(fpath) if x[-4:] == '.hkl']\n",
    "train_bad = [x[:-4] for x in os.listdir('/Volumes/John/data/train-17k-may2023/bad/')]\n",
    "x_files = [x for x in x_files  if x not in train_bad]\n",
    "#x_files = [x for x in x_files if x[:4] == '5969']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9100f9c1-55d1-44bc-968c-bec4f6256e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04386421 0.06575633 0.07844093 0.2223032  0.11906344 0.18196905\n",
      " 0.20939553 0.24083103 0.24951214 0.16221696 0.04650502 0.60427976\n",
      " 0.32973275 0.27134252 0.07327386 0.2455598  0.24252762] (12, 128, 128, 17)\n"
     ]
    }
   ],
   "source": [
    "x = hkl.load(\"/Volumes/John/data/output-large-ard-x/228876305.hkl\")\n",
    "print(np.mean(x, axis = (0, 1, 2)), x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b620fb00-ccea-44a5-9dad-91501d1fc169",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpreprocess(x):\n",
    "    x[..., -1] += 0.7193834232943873\n",
    "    x[..., -1] /= 2\n",
    "    \n",
    "    \n",
    "    #out[-1] -= 0.7193834232943873\n",
    "    x[..., -2] += 0.09731556326714398\n",
    "    x[..., -3] += 0.4973397113668104,\n",
    "    x[..., -4] += 0.1409399364817101\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "220a35d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def normalize_subtile(subtile):\n",
    "    for band in range(0, subtile.shape[-1]):\n",
    "        mins = min_all[band]\n",
    "        maxs = max_all[band]\n",
    "        subtile[..., band] = np.clip(subtile[..., band], mins, maxs)\n",
    "        midrange = (maxs + mins) / 2\n",
    "        rng = maxs - mins\n",
    "        standardized = (subtile[..., band] - midrange) / (rng / 2)\n",
    "        subtile[..., band] = standardized\n",
    "    return subtile\n",
    "\n",
    "def denormalize_subtile(subtile):\n",
    "    for band in range(0, subtile.shape[-1]):\n",
    "        mins = min_all[band]\n",
    "        maxs = max_all[band]\n",
    "        midrange = (maxs + mins) / 2\n",
    "        rng = maxs - mins\n",
    "        standardized = subtile[..., band] * (rng / 2)\n",
    "        standardized = standardized + midrange\n",
    "        subtile[..., band] = standardized\n",
    "    return subtile\n",
    "    \n",
    "    \n",
    "def make_and_smooth_indices(arr):\n",
    "    \"\"\"Calculates remote sensing indices\n",
    "    (evi, bi, msavi2, grndvi) and smooths them\n",
    "    with the Whittaker smoother\n",
    "    \"\"\"\n",
    "    def _make_indices(arr):\n",
    "        indices = np.zeros(\n",
    "            (arr.shape[0], arr.shape[1], arr.shape[2], 4), dtype = np.float32\n",
    "        )\n",
    "        indices[:, ..., 0] = evi(arr)\n",
    "        indices[:, ...,  1] = bi(arr)\n",
    "        indices[:, ...,  2] = msavi2(arr)\n",
    "        indices[:, ...,  3] = grndvi(arr)\n",
    "        return indices\n",
    "\n",
    "    sm_indices = Smoother(lmbd = 50, \n",
    "                          size = 12, \n",
    "                          nbands = 4, \n",
    "                          dimx = arr.shape[1],\n",
    "                          dimy = arr.shape[2], \n",
    "                          outsize = 12)\n",
    "\n",
    "    indices = _make_indices(arr)\n",
    "    indices = sm_indices.interpolate_array(indices)\n",
    "    return indices\n",
    "\n",
    "\n",
    "def load_individual_sample(fpath, ypath, f):\n",
    "    ishkl = os.path.exists(fpath + f + '.hkl')\n",
    "    if ishkl:\n",
    "        x = hkl.load(fpath + f + '.hkl')\n",
    "        if np.max(x) > 3:\n",
    "            x = x / 65535\n",
    "        \n",
    "    else:\n",
    "        x = np.load(fpath + f + \".npy\")\n",
    "        if np.max(x) > 3:\n",
    "            x = x / 65535\n",
    "    preprocess = True\n",
    "    if not preprocess:\n",
    "        x = unpreprocess(x)\n",
    "        x = np.clip(x, 0, 1)\n",
    "    if x.shape[-1] == 13:\n",
    "        i = make_and_smooth_indices(x)\n",
    "        out = np.zeros((x.shape[0], x.shape[1], x.shape[2], 17), dtype = np.float32)\n",
    "        out[..., :13] = x \n",
    "        out[..., 13:] = i\n",
    "    else:\n",
    "        out = x\n",
    "        out[..., -1] *= 2\n",
    "        out[..., -1] -= 0.7193834232943873\n",
    "        \n",
    "        out[..., -2] -= 0.09731556326714398\n",
    "        out[..., -3] -= 0.4973397113668104,\n",
    "        out[..., -4] -= 0.1409399364817101\n",
    "            #out[]\n",
    "\n",
    "    median = np.median(out, axis = 0)\n",
    "    out = np.reshape(out, (4, 3, out.shape[1], out.shape[2], out.shape[3]))\n",
    "    out = np.median(out, axis = 1, overwrite_input = True)\n",
    "    out = np.concatenate([out, median[np.newaxis]], axis = 0)\n",
    "    if os.path.exists(ypath + f + '.tif'):\n",
    "        y = rs.open(ypath + f + '.tif').read(1)\n",
    "    elif os.path.exists(ypath + f + '.npy'):\n",
    "        y = np.load(ypath + f + '.npy')\n",
    "    else:\n",
    "        print(f\"{f} Y does not exist\")\n",
    "        y = np.zeros((14, 14))\n",
    "    if np.max(y) < 10:\n",
    "        y = y * 255\n",
    "    if np.max(y) > 1:\n",
    "        y = y / 255\n",
    "\n",
    "    if os.path.exists(fpath + f + \".tif\"):\n",
    "        img = rs.open(fpath + f + \".tif\").read()\n",
    "        img = np.moveaxis(img, 0, 2)\n",
    "    else:\n",
    "        img = np.zeros_like(y)\n",
    "    #return out[:, 2:-2, 2:-2, :], y, img\n",
    "    if out.shape[1] >= SIZE:\n",
    "        bord_clip = (out.shape[1]-  SIZE) // 2\n",
    "        if bord_clip > 0:\n",
    "            return normalize_subtile(out[:, bord_clip:-bord_clip, bord_clip:-bord_clip :]), y, img\n",
    "        else:\n",
    "            return normalize_subtile(out), y, img\n",
    "    else:\n",
    "        pad = (SIZE - out.shape[1]) // 2\n",
    "        out = np.pad(out, ((0, 0), (pad, pad), (pad, pad), (0, 0)), mode='reflect')\n",
    "        return normalize_subtile(out), y, img\n",
    "        \n",
    "#x_files = ['5969114442']\n",
    "x, y, img = load_individual_sample(fpath, ypath, '228876305')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50f4744b-152b-4d79-ba94-017f3474c5f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot: {plot}, Georeference: {georeference}, {len(x_files)} files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kk/09dbtcq15sb84xb9mrj4g1s00000gp/T/ipykernel_50705/622740918.py:21: TqdmDeprecationWarning: Please use `tqdm.notebook.trange` instead of `tqdm.tnrange`\n",
      "  for i in tnrange(len(x_files)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b39bb0e7b0524d89853dbc4002ce04d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20874 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-26 09:14:50.682169: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n",
      "2024-02-26 09:14:50.686842: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2024-02-26 09:14:50.687075: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "loc(\"mps_select\"(\"(mpsFileLoc): /AppleInternal/Library/BuildRoots/4e1473ee-9f66-11ee-8daf-cedaeb4cabe2/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShadersGraph/mpsgraph/MetalPerformanceShadersGraph/Core/Files/MPSGraphUtilities.mm\":294:0)): error: 'anec.gain_offset_control' op result #0 must be 4D/5D memref of 16-bit float or 8-bit signed integer or 8-bit unsigned integer values, but got 'memref<1x1x1x1xi1>'\n",
      "loc(\"mps_select\"(\"(mpsFileLoc): /AppleInternal/Library/BuildRoots/4e1473ee-9f66-11ee-8daf-cedaeb4cabe2/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShadersGraph/mpsgraph/MetalPerformanceShadersGraph/Core/Files/MPSGraphUtilities.mm\":294:0)): error: 'anec.gain_offset_control' op result #0 must be 4D/5D memref of 16-bit float or 8-bit signed integer or 8-bit unsigned integer values, but got 'memref<1x1x1x1xi1>'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1, 228876300, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "157, 230967906, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "1137, 230967907, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "1159, 20920241, Ran into operands could not be broadcast together with shapes (14,14) (76,76) \n",
      "1297, 228876301, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "1337, 228876303, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "1448, 230967905, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "1450, 20820243, Ran into operands could not be broadcast together with shapes (14,14) (48,48) \n",
      "1741, 2172432018, Ran into operands could not be broadcast together with shapes (14,14) (76,76) \n",
      "1829, 1638108804, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "2109, 1638108805, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "2274, 2162442021, Ran into operands could not be broadcast together with shapes (14,14) (76,76) \n",
      "2463, 20920242, Ran into operands could not be broadcast together with shapes (14,14) (76,76) \n",
      "2485, 20820242, Ran into operands could not be broadcast together with shapes (14,14) (48,48) \n",
      "2487, 230967904, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "2531, 2162452018, Ran into operands could not be broadcast together with shapes (14,14) (76,76) \n",
      "2605, 228876302, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "2713, 230967900, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "2720, 20820246, Ran into operands could not be broadcast together with shapes (14,14) (48,48) \n",
      "2728, 20920246, Ran into operands could not be broadcast together with shapes (14,14) (76,76) \n",
      "3125, 2172422018, Ran into operands could not be broadcast together with shapes (14,14) (76,76) \n",
      "3166, 1638108801, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "3344, 1638108800, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "3567, 2162442018, Ran into operands could not be broadcast together with shapes (14,14) (76,76) \n",
      "3768, 20920247, Ran into operands could not be broadcast together with shapes (14,14) (76,76) \n",
      "3792, 230967901, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "3795, 2162452021, Ran into operands could not be broadcast together with shapes (14,14) (76,76) \n",
      "Skipping 3826, (1, 5, 76, 71, 17)\n",
      "3949, 228876305, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "3991, 20920245, Ran into operands could not be broadcast together with shapes (14,14) (76,76) \n",
      "4012, 230967903, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "4021, 20820245, Ran into operands could not be broadcast together with shapes (14,14) (48,48) \n",
      "4432, 1638108802, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "4665, 1638108803, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "5102, 20820244, Ran into operands could not be broadcast together with shapes (14,14) (48,48) \n",
      "5107, 230967902, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "5117, 20920250, Ran into operands could not be broadcast together with shapes (14,14) (76,76) \n",
      "5129, 20920244, Ran into operands could not be broadcast together with shapes (14,14) (76,76) \n",
      "5178, 228876304, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "5254, 369127905, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "5465, 238294404, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "5552, 20420245, Ran into operands could not be broadcast together with shapes (14,14) (48,48) \n",
      "5764, 1668107603, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "6011, 1668107602, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "6042, 2162462018, Ran into operands could not be broadcast together with shapes (14,14) (76,76) \n",
      "6171, 20520244, Ran into operands could not be broadcast together with shapes (14,14) (48,48) \n",
      "6184, 20420244, Ran into operands could not be broadcast together with shapes (14,14) (48,48) \n",
      "6334, 238294405, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "6489, 369127904, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "6842, 20520246, Ran into operands could not be broadcast together with shapes (14,14) (48,48) \n",
      "6871, 20420246, Ran into operands could not be broadcast together with shapes (14,14) (48,48) \n",
      "7058, 1668107600, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "7245, 1668107601, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "7430, 20420247, Ran into operands could not be broadcast together with shapes (14,14) (48,48) \n",
      "7811, 369127903, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "7923, 238294402, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "8115, 20520243, Ran into operands could not be broadcast together with shapes (14,14) (48,48) \n",
      "8137, 20420243, Ran into operands could not be broadcast together with shapes (14,14) (48,48) \n",
      "8251, 1668107605, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "Skipping 8343, (1, 5, 76, 73, 17)\n",
      "1351911362020 Y does not exist\n",
      "8498, 1668107604, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "8597, 20420242, Ran into operands could not be broadcast together with shapes (14,14) (48,48) \n",
      "8624, 20520242, Ran into operands could not be broadcast together with shapes (14,14) (48,48) \n",
      "8847, 238294403, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "8937, 369127902, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "9080, 369127900, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "9087, 2172412018, Ran into operands could not be broadcast together with shapes (14,14) (76,76) \n",
      "9177, 238294401, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "9491, 1668107606, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "9813, 1668107607, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "9913, 20520241, Ran into operands could not be broadcast together with shapes (14,14) (48,48) \n",
      "9929, 20420241, Ran into operands could not be broadcast together with shapes (14,14) (48,48) \n",
      "10117, 238294400, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "10219, 369127901, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "10331, 2162432021, Ran into operands could not be broadcast together with shapes (14,14) (76,76) \n",
      "10391, 1637108805, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "10461, 2162422018, Ran into operands could not be broadcast together with shapes (14,14) (76,76) \n",
      "10916, 2172442018, Ran into operands could not be broadcast together with shapes (14,14) (76,76) \n",
      "11415, 1637108804, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "11914, 449123905, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "12186, 228371404, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "12407, 449123904, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "12928, 1637108803, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "13158, 449123900, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "13392, 228371400, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "13531, 228371401, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "13759, 449123901, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "13984, 1637108802, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "14158, 2162432018, Ran into operands could not be broadcast together with shapes (14,14) (76,76) \n",
      "14264, 1637108800, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "14294, 2162422021, Ran into operands could not be broadcast together with shapes (14,14) (76,76) \n",
      "14460, 449123903, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "14717, 228371403, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "14801, 228371402, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "14995, 2172452018, Ran into operands could not be broadcast together with shapes (14,14) (76,76) \n",
      "15058, 20420248, Ran into operands could not be broadcast together with shapes (14,14) (48,48) \n",
      "15088, 449123902, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "15280, 1637108801, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "15431, 359128105, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "15553, 20920249, Ran into operands could not be broadcast together with shapes (14,14) (76,76) \n",
      "15583, 465124601, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "15731, 371127700, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "15986, 445124105, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "16117, 1642114002, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "16144, 1642114003, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "16247, 445124104, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "16319, 20720241, Ran into operands could not be broadcast together with shapes (14,14) (48,48) \n",
      "16549, 371127701, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "16674, 465124600, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "16682, 20920248, Ran into operands could not be broadcast together with shapes (14,14) (76,76) \n",
      "16808, 359128104, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "16863, 359128106, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "16997, 465124602, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "17137, 371127703, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "17312, 2162412018, Ran into operands could not be broadcast together with shapes (14,14) (76,76) \n",
      "17350, 20720243, Ran into operands could not be broadcast together with shapes (14,14) (48,48) \n",
      "17486, 1642114001, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "17564, 1642114000, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "17717, 20720242, Ran into operands could not be broadcast together with shapes (14,14) (48,48) \n",
      "17904, 371127702, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "18033, 465124603, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "18189, 359128107, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "18291, 448123900, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "18292, 359128103, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "18561, 371127706, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "18661, 2162412021, Ran into operands could not be broadcast together with shapes (14,14) (76,76) \n",
      "18734, 445124103, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "18803, 1642114004, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "18940, 1642114005, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "18993, 445124102, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "19161, 371127707, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "19220, 21020241, Ran into operands could not be broadcast together with shapes (14,14) (76,76) \n",
      "19293, 2172462018, Ran into operands could not be broadcast together with shapes (14,14) (76,76) \n",
      "19387, 465124606, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "19430, 359128102, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "19431, 448123901, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "19586, 359128100, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "19588, 448123903, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "19844, 371127705, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "19984, 20720245, Ran into operands could not be broadcast together with shapes (14,14) (48,48) \n",
      "20050, 445124100, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "20147, 1642114007, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "20254, 1642114006, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "20365, 445124101, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "20421, 20720244, Ran into operands could not be broadcast together with shapes (14,14) (48,48) \n",
      "20535, 371127704, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "20575, 21020242, Ran into operands could not be broadcast together with shapes (14,14) (76,76) \n",
      "20775, 465124605, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "20820, 448123902, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n",
      "20821, 359128101, Ran into operands could not be broadcast together with shapes (14,14) (68,68) \n"
     ]
    }
   ],
   "source": [
    "## LEN = 4\n",
    "from tqdm import tnrange\n",
    "#x_batch_test = augment_sample(x[0])\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "best_xs = []\n",
    "best_ys = []\n",
    "names = []\n",
    "output_size = SIZE - 14\n",
    "label_size = 14\n",
    "start = (output_size - label_size) // 2\n",
    "plot = False\n",
    "georeference = True\n",
    "\n",
    "print(f\"Plot: {plot}, Georeference: {georeference}, {len(x_files)} files\")\n",
    "for i in tnrange(len(x_files)):\n",
    "#for i, val in test_data.iterrows():\n",
    "    if os.path.exists(f\"/Volumes/John/data/train-17k-may2023/figs/{x_files[i]}.png\"):\n",
    "        try:\n",
    "            #fpath = '/Volumes/John/data/output-large-ard-x/'\n",
    "            batch_x, y, img = load_individual_sample(fpath, ypath, x_files[i])\n",
    "            batch_x = batch_x[np.newaxis]\n",
    "            lengths = np.full((batch_x.shape[0]), 4)\n",
    "            if np.prod(batch_x.shape[2:4]) == (76*76):\n",
    "                preds = predict_sess.run(predict_logits,\n",
    "                                      feed_dict={predict_inp:batch_x, \n",
    "                                                 predict_length:lengths})\n",
    "                pred_tc = np.mean(preds.squeeze()[start:start+label_size, start:start + label_size])\n",
    "                lab_tc = np.mean(y)\n",
    "                if georeference:\n",
    "                    best_iou = 0.\n",
    "                    best_x = 0.\n",
    "                    best_y = 0.\n",
    "                    iter = 0\n",
    "                    for xs in [0, -1, 1]:\n",
    "                        for ys in [0, -1, 1]:\n",
    "                            pred_tc = preds.squeeze()[start+xs:start+label_size+xs, start+ys:start + label_size+ys]\n",
    "                            intersection = pred_tc * y\n",
    "                            union = np.maximum(pred_tc, y)\n",
    "                            iou = np.mean(intersection) / np.mean(union)\n",
    "                            if iter == 0:\n",
    "                                middle_iou = iou\n",
    "                            if iou > (best_iou + 0.005) and iou > (middle_iou + 0.02):\n",
    "                                best_iou = iou\n",
    "                                best_x = xs\n",
    "                                best_y = ys\n",
    "                            iter += 1\n",
    "                    best_xs.append(best_x)\n",
    "                    best_ys.append(best_y)\n",
    "                    names.append(x_files[i])\n",
    "                if plot and abs(pred_tc - lab_tc) >= 0.0:\n",
    "                    fig, axs = plt.subplots(2, 2, figsize = (9, 9))\n",
    "                    sns.heatmap(preds.squeeze(), vmin = 0.0, vmax = 1, ax=axs[0, 1], cbar = False)\n",
    "                    sns.heatmap(preds.squeeze()[start:start+14, start:start+14], vmin = 0.0, vmax = 1, ax=axs[1, 0], cbar = False)\n",
    "                    sns.heatmap(y, vmin = 0.0, vmax = 1, ax=axs[1, 1], cbar = False)\n",
    "                    isns.imgplot(img, ax = axs[0, 0])\n",
    "                    axs[0,0].set_title(f'{i}, model {np.mean(preds)}')\n",
    "                    #ax2.set_title(f'136, {np.mean(preds2)}')\n",
    "                    axs[1, 0].set_title(np.mean(preds.squeeze()[start:start+14, start:start+14]))\n",
    "                    axs[1, 1].set_title(np.mean(y))\n",
    "                    #ax4.set_title(np.mean(test_y[i]))\n",
    "                    #plt.show()\n",
    "                    \n",
    "                    plt.savefig(f\"/Volumes/John/data/train-17k-may2023/figs/{x_files[i]}\")\n",
    "                    plt.close()\n",
    "            else:\n",
    "                print(f\"Skipping {i}, {batch_x.shape}\")\n",
    "        #to_keep.append(i)\n",
    "        except KeyboardInterrupt:\n",
    "                print('Interrupted')\n",
    "                try:\n",
    "                    sys.exit(130)\n",
    "                except SystemExit:\n",
    "                    os._exit(130)\n",
    "        except Exception as e:\n",
    "            print(f\"{i}, {x_files[i]}, Ran into {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87427c68-b28e-44c7-a493-ee238a2e2c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfout = pd.DataFrame({'name':names, 'bestx':best_xs, 'besty':best_ys})\n",
    "dfout.head(10)\n",
    "dfout.to_csv(\"georeferencer_20k.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f18c5e4-6b28-4c86-818a-5dd8c506bca7",
   "metadata": {},
   "source": [
    "import rasterio as rs\n",
    "with rs.open('../../HighResCanopyHeight/data/images2/ppcclip.tif') as f:\n",
    "    profile = f.profile.copy()\n",
    "    transform = f.bounds\n",
    "    \n",
    "    data = f.read()\n",
    "    data = data.reshape(3, 1566 // 2, 2, 1482 // 2, 2)\n",
    "    data = np.mean(data, axis = (2, 4))\n",
    "    data = data.astype(np.uint8)\n",
    "    newtransform = rs.transform.from_bounds(f.bounds[0], f.bounds[1], f.bounds[2], f.bounds[3], data.shape[2], data.shape[1])\n",
    "    print(data.shape, np.max(data), data.dtype)\n",
    "    # And then change the band count to 1, set the\n",
    "    # dtype to uint8, and specify LZW compression.\n",
    "    profile.update(\n",
    "        dtype=rs.uint8,\n",
    "        count=3,\n",
    "        height = data.shape[1],\n",
    "        width = data.shape[2],\n",
    "        transform = newtransform,\n",
    "        compress='lzw')\n",
    "    print(profile)\n",
    "\n",
    "    with rs.open('example.tif', 'w', **profile) as dst:\n",
    "        dst.write(data.astype(rs.uint8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8285057-804a-430f-8fc5-06df86944b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#xs = np.load(\"train_xs.npy\")\n",
    "#train_xs = [x[:-4] for x in os.listdir(\"/Volumes/John/data/train-17k-may2023/figs/\") if x[-4:] == '.png']\n",
    "#train_xs = [x for x in train_xs  if x not in train_bad]\n",
    "#print(len(train_xs))\n",
    "#np.save(\"train_xs.npy\", train_xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56d8a18d-8199-4ef8-9e17-5298b916ebbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_xs = [x[:-4] for x in os.listdir(\"/Volumes/John/data/train-17k-may2023/remove/\") if x[-4:] == '.png']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8587e395-bbef-4916-9653-bfbe9f29520d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.array(train_xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cdd14f9d-f5ad-4d8e-9691-aa166fc34d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(train_xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d130f4db-0fa6-4078-8fd2-fa2be89afffb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2-9",
   "language": "python",
   "name": "tf2-9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
