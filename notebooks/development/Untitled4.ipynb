{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d49a1f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import math\n",
    "\n",
    "class LocalContextNorm(nn.Module):\n",
    "    def __init__(self, num_features, channels_per_group=5, window_size=(5, 5), eps=1e-5):\n",
    "        super(LocalContextNorm, self).__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(1, num_features, 1, 1))\n",
    "        self.bias = nn.Parameter(torch.zeros(1, num_features, 1, 1))\n",
    "        self.channels_per_group = channels_per_group\n",
    "        self.eps = eps\n",
    "        self.window_size = window_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.size()\n",
    "        G = C // self.channels_per_group\n",
    "        assert C % self.channels_per_group == 0\n",
    "        if self.window_size[0] < H and self.window_size[1] < W:\n",
    "            # Build integral image\n",
    "            device = torch.device(torch.cuda.current_device() if torch.cuda.is_available() else 'cpu')\n",
    "            x_squared = x * x\n",
    "            integral_img = x.cumsum(dim=2).cumsum(dim=3)\n",
    "            \n",
    "            print(\"Integral IMG\", integral_img.shape)\n",
    "            integral_img_sq = x_squared.cumsum(dim=2).cumsum(dim=3)\n",
    "            print(\"Integral IMG sq\", integral_img.shape)\n",
    "            # Dilation\n",
    "            d = (1, self.window_size[0], self.window_size[1])\n",
    "            integral_img = torch.unsqueeze(integral_img, dim=1)\n",
    "            integral_img_sq = torch.unsqueeze(integral_img_sq, dim=1)\n",
    "            print(\"Integral IMG\", integral_img.shape)\n",
    "            print(\"Integral IMG sq\", integral_img.shape)\n",
    "            kernel = torch.tensor([[[[[1., -1.], [-1., 1.]]]]]).to(device)\n",
    "            c_kernel = torch.ones((1, 1, self.channels_per_group, 1, 1)).to(device)\n",
    "            with torch.no_grad():\n",
    "                # Dilated conv\n",
    "                sums = F.conv3d(integral_img, kernel, stride=[1, 1, 1], dilation=d)\n",
    "                sums = F.conv3d(sums, c_kernel, stride=[self.channels_per_group, 1, 1])\n",
    "                squares = F.conv3d(integral_img_sq, kernel, stride=[1, 1, 1], dilation=d)\n",
    "                squares = F.conv3d(squares, c_kernel, stride=[self.channels_per_group, 1, 1])\n",
    "            print(\"Sums\", sums.shape)\n",
    "            print(\"Squares\", squares.shape)\n",
    "            n = self.window_size[0] * self.window_size[1] * self.channels_per_group\n",
    "            means = torch.squeeze(sums / n, dim=1)\n",
    "            var = torch.squeeze((1.0 / n * (squares - sums * sums / n)), dim=1)\n",
    "            print(\"Means\", means.shape)\n",
    "            print(\"Var\", var.shape)\n",
    "            _, _, h, w = means.size()\n",
    "            pad2d = (int(math.floor((W - w) / 2)), int(math.ceil((W - w) / 2)), int(math.floor((H - h) / 2)),\n",
    "                     int(math.ceil((H - h) / 2)))\n",
    "            padded_means = F.pad(means, pad2d, 'replicate')\n",
    "            padded_vars = F.pad(var, pad2d, 'replicate') + self.eps\n",
    "            print(\"Means\", padded_means.shape)\n",
    "            print(\"Var\", padded_vars.shape)\n",
    "            for i in range(G):\n",
    "                x[:, i * self.channels_per_group:i * self.channels_per_group + self.channels_per_group, :, :] = \\\n",
    "                    (x[:, i * self.channels_per_group:i * self.channels_per_group + self.channels_per_group, :, :] -\n",
    "                     torch.unsqueeze(padded_means[:, i, :, :], dim=1).to(device)) /\\\n",
    "                    ((torch.unsqueeze(padded_vars[:, i, :, :], dim=1)).to(device)).sqrt()\n",
    "            del integral_img\n",
    "            del integral_img_sq\n",
    "        else:\n",
    "            x = x.view(N, G, -1)\n",
    "            mean = x.mean(-1, keepdim=True)\n",
    "            var = x.var(-1, keepdim=True)\n",
    "            x = (x - mean) / (var + self.eps).sqrt()\n",
    "            x = x.view(N, C, H, W)\n",
    "\n",
    "        return x * self.weight + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "07ad8e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integral IMG torch.Size([1, 40, 28, 28])\n",
      "Integral IMG sq torch.Size([1, 40, 28, 28])\n",
      "Integral IMG torch.Size([1, 1, 40, 28, 28])\n",
      "Integral IMG sq torch.Size([1, 1, 40, 28, 28])\n",
      "Sums torch.Size([1, 1, 8, 23, 23])\n",
      "Squares torch.Size([1, 1, 8, 23, 23])\n",
      "Means torch.Size([1, 8, 23, 23])\n",
      "Var torch.Size([1, 8, 23, 23])\n",
      "Means torch.Size([1, 8, 28, 28])\n",
      "Var torch.Size([1, 8, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "out = torch.zeros((1, 40, 28, 28))\n",
    "l = LocalContextNorm(num_features = 40)(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c180124",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
