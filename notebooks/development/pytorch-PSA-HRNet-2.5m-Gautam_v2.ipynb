{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0093d353",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch._utils\n",
    "from torch.nn import init\n",
    "import numpy as np\n",
    "import torch.optim\n",
    "import os\n",
    "from sys import path\n",
    "path.append(r\"C:\\Users\\Gautam.Mathur\")\n",
    "from carafe import CARAFE\n",
    "\n",
    "# From: https://arxiv.org/pdf/2107.00782v2.pdf\n",
    "class PSA_p(nn.Module):\n",
    "\n",
    "    def __init__(self, channel=512):\n",
    "        super().__init__()\n",
    "        self.ch_wv=nn.Conv2d(channel,channel//2,kernel_size=(1,1))\n",
    "        self.ch_wq=nn.Conv2d(channel,1,kernel_size=(1,1))\n",
    "        self.softmax_channel=nn.Softmax(1)\n",
    "        self.softmax_spatial=nn.Softmax(-1)\n",
    "        self.ch_wz=nn.Conv2d(channel//2,channel,kernel_size=(1,1))\n",
    "        self.ln=nn.LayerNorm(channel)\n",
    "        self.sigmoid=nn.Sigmoid()\n",
    "        self.sp_wv=nn.Conv2d(channel,channel//2,kernel_size=(1,1))\n",
    "        self.sp_wq=nn.Conv2d(channel,channel//2,kernel_size=(1,1))\n",
    "        self.agp=nn.AdaptiveAvgPool2d((1,1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.size()\n",
    "\n",
    "        #Channel-only Self-Attention\n",
    "        channel_wv=self.ch_wv(x) #bs,c//2,h,w\n",
    "        channel_wq=self.ch_wq(x) #bs,1,h,w\n",
    "        channel_wv=channel_wv.reshape(b,c//2,-1) #bs,c//2,h*w\n",
    "        channel_wq=channel_wq.reshape(b,-1,1) #bs,h*w,1\n",
    "        channel_wq=self.softmax_channel(channel_wq)\n",
    "        channel_wz=torch.matmul(channel_wv,channel_wq).unsqueeze(-1) #bs,c//2,1,1\n",
    "        channel_weight=self.sigmoid(self.ln(self.ch_wz(channel_wz).reshape(b,c,1).permute(0,2,1))).permute(0,2,1).reshape(b,c,1,1) #bs,c,1,1\n",
    "        channel_out=channel_weight*x\n",
    "\n",
    "        #Spatial-only Self-Attention\n",
    "        spatial_wv=self.sp_wv(x) #bs,c//2,h,w\n",
    "        spatial_wq=self.sp_wq(x) #bs,c//2,h,w\n",
    "        spatial_wq=self.agp(spatial_wq) #bs,c//2,1,1\n",
    "        spatial_wv=spatial_wv.reshape(b,c//2,-1) #bs,c//2,h*w\n",
    "        spatial_wq=spatial_wq.permute(0,2,3,1).reshape(b,1,c//2) #bs,1,c//2\n",
    "        spatial_wq=self.softmax_spatial(spatial_wq)\n",
    "        spatial_wz=torch.matmul(spatial_wq,spatial_wv) #bs,1,h*w\n",
    "        spatial_weight=self.sigmoid(spatial_wz.reshape(b,1,h,w)) #bs,1,h,w\n",
    "        spatial_out=spatial_weight*x\n",
    "        out=spatial_out+channel_out\n",
    "        return out\n",
    "\n",
    "class PFC(nn.Module):\n",
    "    def __init__(self,channels, kernel_size=7):\n",
    "        super(PFC, self).__init__()\n",
    "        self.depthwise = nn.Sequential(\n",
    "                    nn.Conv2d(32, channels, kernel_size,\n",
    "                              groups=channels, padding= kernel_size // 2, bias = False),\n",
    "                    nn.BatchNorm2d(channels))\n",
    "        self.pointwise = nn.Sequential(\n",
    "                    nn.Conv2d(32, channels, kernel_size=1, bias = False),\n",
    "                    nn.BatchNorm2d(channels),\n",
    "                    nn.Mish(inplace=True))\n",
    "        self.act = nn.Mish()\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = self.depthwise(x)\n",
    "        x += residual\n",
    "        x = self.act(x)\n",
    "        x = self.pointwise(x)\n",
    "        return x\n",
    "\n",
    "def _make_pair(value):\n",
    "    if isinstance(value, int):\n",
    "        value = (value,) * 2\n",
    "    return value\n",
    "\n",
    "\n",
    "def conv_layer(in_channels,\n",
    "               out_channels,\n",
    "               kernel_size,\n",
    "               bias=True):\n",
    "    \"\"\"\n",
    "    Re-write convolution layer for adaptive `padding`.\n",
    "    \"\"\"\n",
    "    kernel_size = _make_pair(kernel_size)\n",
    "    padding = (int((kernel_size[0] - 1) / 2), \n",
    "               int((kernel_size[1] - 1) / 2))\n",
    "    return nn.Conv2d(in_channels,\n",
    "                     out_channels,\n",
    "                     kernel_size,\n",
    "                     padding=padding,\n",
    "                     bias=bias)\n",
    "\n",
    "\n",
    "def sequential(*args):\n",
    "    \"\"\"\n",
    "    Modules will be added to the a Sequential Container in the order they\n",
    "    are passed.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    args: Definition of Modules in order.\n",
    "    -------\n",
    "    \"\"\"\n",
    "    if len(args) == 1:\n",
    "        if isinstance(args[0], OrderedDict):\n",
    "            raise NotImplementedError(\n",
    "                'sequential does not support OrderedDict input.')\n",
    "        return args[0]\n",
    "    modules = []\n",
    "    for module in args:\n",
    "        if isinstance(module, nn.Sequential):\n",
    "            for submodule in module.children():\n",
    "                modules.append(submodule)\n",
    "        elif isinstance(module, nn.Module):\n",
    "            modules.append(module)\n",
    "    return nn.Sequential(*modules)\n",
    "\n",
    "\n",
    "class Conv(nn.Module):\n",
    "    # The basic building block follows conv bn relu, with activation after bn\n",
    "    def __init__(self, nIn, nOut, kSize, stride, padding, dilation=(1, 1), groups=1, bn_acti=False, bias=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.bn_acti = bn_acti\n",
    "        \n",
    "        self.conv = nn.Conv2d(nIn, nOut, kernel_size = kSize,\n",
    "                              stride=stride, padding=padding,\n",
    "                              dilation=dilation,groups=groups,bias=bias)\n",
    "        \n",
    "        if self.bn_acti:\n",
    "            self.bn_relu = BNPReLU(nOut)\n",
    "            \n",
    "    def forward(self, input):\n",
    "        output = self.conv(input)\n",
    "\n",
    "        if self.bn_acti:\n",
    "            output = self.bn_relu(output)\n",
    "\n",
    "        return output  \n",
    "    \n",
    "    \n",
    "class BNPReLU(nn.Module):\n",
    "    def __init__(self, nIn):\n",
    "        super().__init__()\n",
    "        self.bn = nn.BatchNorm2d(nIn)\n",
    "        self.acti = nn.Mish(nIn)\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.bn(input)\n",
    "        output = self.acti(output)\n",
    "        \n",
    "        return output\n",
    "\n",
    "\n",
    "class self_attn(nn.Module):\n",
    "    def __init__(self, in_channels, mode='hw'):\n",
    "        super(self_attn, self).__init__()\n",
    "\n",
    "        self.mode = mode\n",
    "\n",
    "        self.query_conv = Conv(in_channels, in_channels // 8, kSize=(1, 1),stride=1,padding=0)\n",
    "        self.key_conv = Conv(in_channels, in_channels // 8, kSize=(1, 1),stride=1,padding=0)\n",
    "        self.value_conv = Conv(in_channels, in_channels, kSize=(1, 1),stride=1,padding=0)\n",
    "\n",
    "        self.gamma = nn.Parameter(torch.zeros(1))\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size, channel, height, width = x.size()\n",
    "\n",
    "        axis = 1\n",
    "        if 'h' in self.mode:\n",
    "            axis *= height\n",
    "        if 'w' in self.mode:\n",
    "            axis *= width\n",
    "\n",
    "        view = (batch_size, -1, axis)\n",
    "\n",
    "        projected_query = self.query_conv(x).view(*view).permute(0, 2, 1)\n",
    "        projected_key = self.key_conv(x).view(*view)\n",
    "\n",
    "        attention_map = torch.bmm(projected_query, projected_key)\n",
    "        attention = self.sigmoid(attention_map)\n",
    "        projected_value = self.value_conv(x).view(*view)\n",
    "\n",
    "        out = torch.bmm(projected_value, attention.permute(0, 2, 1))\n",
    "        out = out.view(batch_size, channel, height, width)\n",
    "\n",
    "        out = self.gamma * out + x\n",
    "        return out\n",
    "\n",
    "# Axial attention from: https://arxiv.org/pdf/1912.12180.pdf\n",
    "class AA_kernel(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel):\n",
    "        super(AA_kernel, self).__init__()\n",
    "        self.conv0 = Conv(in_channel, out_channel, kSize=1,stride=1,padding=0)\n",
    "        self.conv1 = Conv(out_channel, out_channel, kSize=(3, 3),stride = 1, padding=1)\n",
    "        self.Hattn = self_attn(out_channel, mode='h')\n",
    "        self.Wattn = self_attn(out_channel, mode='w')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv0(x)\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        Hx = self.Hattn(x)\n",
    "        Wx = self.Wattn(Hx)\n",
    "\n",
    "        return Wx\n",
    "\n",
    "# Pixelshuffle block from: https://arxiv.org/pdf/1609.05158v2.pdf\n",
    "def pixelshuffle_block(in_channels,\n",
    "                       out_channels,\n",
    "                       upscale_factor=2,\n",
    "                       kernel_size=3):\n",
    "    \"\"\"\n",
    "    Upsample features according to `upscale_factor`.\n",
    "    \"\"\"\n",
    "    conv = conv_layer(in_channels,\n",
    "                      out_channels * (upscale_factor ** 2),\n",
    "                      kernel_size, bias = False)\n",
    "    pixel_shuffle = nn.PixelShuffle(upscale_factor)\n",
    "    return sequential(conv, pixel_shuffle)\n",
    "\n",
    "    \n",
    "class ResidualPSA(nn.Module):\n",
    "    \"\"\"\n",
    "    Residual block with PSA attention\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels):\n",
    "        super(ResidualPSA, self).__init__()\n",
    "\n",
    "        #if mid_channels is None:\n",
    "        #    mid_channels = in_channels\n",
    "        if out_channels is None:\n",
    "            out_channels = in_channels\n",
    "\n",
    "        #self.c1_r = Conv2dWeightNorm(in_channels, in_channels, 3)\n",
    "        self.c1_r = conv_layer(in_channels, out_channels, 3, bias = False)\n",
    "        self.act = nn.Mish()\n",
    "        #self.c2_r = Conv2dWeightNorm(in_channels, in_channels, 3)\n",
    "        self.c2_r = conv_layer(out_channels, out_channels, 3, bias = False)\n",
    "        self.norm_layer = nn.BatchNorm2d(out_channels) #nn.GroupNorm(4, 32)#nn.BatchNorm2d(32)\n",
    "        self.norm_layer1 = nn.BatchNorm2d(out_channels)#nn.GroupNorm(4, 32)#nn.BatchNorm2d(32)\n",
    "        self.psa = PSA_p(out_channels)\n",
    "        #self.psa2 = PSA_p(out_channels, out_channels)\n",
    "        #self.splat = SplAtConv2d(out_channels, out_channels, 3)\n",
    "        \n",
    "\n",
    "        self.act = nn.Mish()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = (self.c1_r(x))\n",
    "        out = self.norm_layer(out)\n",
    "        out = self.act(out)\n",
    "        #out = self.splat(out)\n",
    "        out = self.psa(out)\n",
    "        \n",
    "\n",
    "        out = (self.c2_r(out))\n",
    "        out = self.norm_layer1(out)\n",
    "        #out = self.psa(out)\n",
    "        \n",
    "        #print(out.shape, x.shape)\n",
    "        out = out + x\n",
    "        #if self.final_relu:\n",
    "        out = self.act(out)\n",
    "        #out = self.psa2(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "def constant_init(module, val, bias=0):\n",
    "    if hasattr(module, 'weight') and module.weight is not None:\n",
    "        nn.init.constant_(module.weight, val)\n",
    "    if hasattr(module, 'bias') and module.bias is not None:\n",
    "        nn.init.constant_(module.bias, bias)\n",
    "\n",
    "\n",
    "def kaiming_init(module,\n",
    "                 a=0,\n",
    "                 mode='fan_out',\n",
    "                 nonlinearity='relu',\n",
    "                 bias=0,\n",
    "                 distribution='normal'):\n",
    "    assert distribution in ['uniform', 'normal']\n",
    "    if distribution == 'uniform':\n",
    "        nn.init.kaiming_uniform_(\n",
    "            module.weight, a=a, mode=mode, nonlinearity=nonlinearity)\n",
    "    else:\n",
    "        nn.init.kaiming_normal_(\n",
    "            module.weight, a=a, mode=mode, nonlinearity=nonlinearity)\n",
    "    if hasattr(module, 'bias') and module.bias is not None:\n",
    "        nn.init.constant_(module.bias, bias)\n",
    "        \n",
    "\n",
    "    \n",
    "class CFPModule(nn.Module):\n",
    "    def __init__(self, nIn, d=1, KSize=3,dkSize=3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.bn_relu_1 = BNPReLU(nIn)\n",
    "        self.bn_relu_2 = BNPReLU(nIn)\n",
    "        self.conv1x1_1 = Conv(nIn, nIn // 4, KSize, 1, padding=1, bn_acti=True)\n",
    "        \n",
    "        self.dconv_4_1 = Conv(nIn //4, nIn //16, (dkSize,dkSize),1,padding = (1*d+1,1*d+1),\n",
    "                            dilation=(d+1,d+1), groups = nIn //16, bn_acti=True)\n",
    "        \n",
    "        self.dconv_4_2 = Conv(nIn //16, nIn //16, (dkSize,dkSize),1,padding = (1*d+1,1*d+1),\n",
    "                            dilation=(d+1,d+1), groups = nIn //16, bn_acti=True)\n",
    "        \n",
    "        self.dconv_4_3 = Conv(nIn //16, nIn //8, (dkSize,dkSize),1,padding = (1*d+1,1*d+1),\n",
    "                            dilation=(d+1,d+1), groups = nIn //16, bn_acti=True)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.dconv_1_1 = Conv(nIn //4, nIn //16, (dkSize,dkSize),1,padding = (1,1),\n",
    "                            dilation=(1,1), groups = nIn //16, bn_acti=True)\n",
    "        \n",
    "        self.dconv_1_2 = Conv(nIn //16, nIn //16, (dkSize,dkSize),1,padding = (1,1),\n",
    "                            dilation=(1,1), groups = nIn //16, bn_acti=True)\n",
    "        \n",
    "        self.dconv_1_3 = Conv(nIn //16, nIn //8, (dkSize,dkSize),1,padding = (1,1),\n",
    "                            dilation=(1,1), groups = nIn //16, bn_acti=True)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.dconv_2_1 = Conv(nIn //4, nIn //16, (dkSize,dkSize),1,padding = (int(d/4+1),int(d/4+1)),\n",
    "                            dilation=(int(d/4+1),int(d/4+1)), groups = nIn //16, bn_acti=True)\n",
    "        \n",
    "        self.dconv_2_2 = Conv(nIn //16, nIn //16, (dkSize,dkSize),1,padding = (int(d/4+1),int(d/4+1)),\n",
    "                            dilation=(int(d/4+1),int(d/4+1)), groups = nIn //16, bn_acti=True)\n",
    "        \n",
    "        self.dconv_2_3 = Conv(nIn //16, nIn //8, (dkSize,dkSize),1,padding = (int(d/4+1),int(d/4+1)),\n",
    "                            dilation=(int(d/4+1),int(d/4+1)), groups = nIn //16, bn_acti=True)\n",
    "        \n",
    "        \n",
    "        self.dconv_3_1 = Conv(nIn //4, nIn //16, (dkSize,dkSize),1,padding = (int(d/2+1),int(d/2+1)),\n",
    "                            dilation=(int(d/2+1),int(d/2+1)), groups = nIn //16, bn_acti=True)\n",
    "        \n",
    "        self.dconv_3_2 = Conv(nIn //16, nIn //16, (dkSize,dkSize),1,padding = (int(d/2+1),int(d/2+1)),\n",
    "                            dilation=(int(d/2+1),int(d/2+1)), groups = nIn //16, bn_acti=True)\n",
    "        \n",
    "        self.dconv_3_3 = Conv(nIn //16, nIn //8, (dkSize,dkSize),1,padding = (int(d/2+1),int(d/2+1)),\n",
    "                            dilation=(int(d/2+1),int(d/2+1)), groups = nIn //16, bn_acti=True)\n",
    "        \n",
    "                      \n",
    "        \n",
    "        self.conv1x1 = Conv(nIn, nIn, 1, 1, padding=0,bn_acti=False)  \n",
    "        \n",
    "    def forward(self, input):\n",
    "        inp = self.bn_relu_1(input)\n",
    "        inp = self.conv1x1_1(inp)\n",
    "        \n",
    "        o1_1 = self.dconv_1_1(inp)\n",
    "        o1_2 = self.dconv_1_2(o1_1)\n",
    "        o1_3 = self.dconv_1_3(o1_2)\n",
    "        \n",
    "        o2_1 = self.dconv_2_1(inp)\n",
    "        o2_2 = self.dconv_2_2(o2_1)\n",
    "        o2_3 = self.dconv_2_3(o2_2)\n",
    "        \n",
    "        o3_1 = self.dconv_3_1(inp)\n",
    "        o3_2 = self.dconv_3_2(o3_1)\n",
    "        o3_3 = self.dconv_3_3(o3_2)\n",
    "        \n",
    "        o4_1 = self.dconv_4_1(inp)\n",
    "        o4_2 = self.dconv_4_2(o4_1)\n",
    "        o4_3 = self.dconv_4_3(o4_2)\n",
    "        \n",
    "        output_1 = torch.cat([o1_1,o1_2,o1_3], 1)\n",
    "        output_2 = torch.cat([o2_1,o2_2,o2_3], 1)      \n",
    "        output_3 = torch.cat([o3_1,o3_2,o3_3], 1)       \n",
    "        output_4 = torch.cat([o4_1,o4_2,o4_3], 1)   \n",
    "        \n",
    "        \n",
    "        ad1 = output_1\n",
    "        ad2 = ad1 + output_2\n",
    "        ad3 = ad2 + output_3\n",
    "        ad4 = ad3 + output_4\n",
    "        output = torch.cat([ad1,ad2,ad3,ad4],1)\n",
    "        output = self.bn_relu_2(output)\n",
    "        output = self.conv1x1(output)\n",
    "        \n",
    "        return output+input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44fd429",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "class HRSupResNet(nn.Module):\n",
    "    \"\"\"\n",
    "    High resolution super resolution network. This approach basically flips the\n",
    "    architecture of HRNet: https://arxiv.org/pdf/1904.04514.pdf\n",
    "    And uses PSA attention in the encoder with CARAFE to upsample\n",
    "    \n",
    "    Carafe: https://openaccess.thecvf.com/content_ICCV_2019/papers/Wang_CARAFE_Content-Aware_ReAssembly_of_FEatures_ICCV_2019_paper.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels=10,\n",
    "                 out_channels=1,\n",
    "                 feature_channels=32,\n",
    "                 upscale=2,\n",
    "                 tenmfeats = 32):\n",
    "        super(HRSupResNet, self).__init__()\n",
    "        \n",
    "        self.lrelu = nn.Mish()\n",
    "        \n",
    "        # 1x -> 2x - this block downsamples the 10m input to 5m\n",
    "        self.feats = nn.Conv2d(in_channels, 32, 1, 1, bias = True)\n",
    "        self.upsampler = CARAFE(32)\n",
    "        self.PSA_p1 = PSA_p(32)\n",
    "        self.PSA_p2 = PSA_p(16)\n",
    "        \n",
    "        # 2x residual blocks\n",
    "        self.block2xb = ResidualPSA(32, 32)\n",
    "        self.block2xc = ResidualPSA(32, 32)\n",
    "        \n",
    "        # 1x residual blocks\n",
    "        self.block1xa = ResidualPSA(tenmfeats, tenmfeats)\n",
    "        self.block1xb = ResidualPSA(tenmfeats, tenmfeats)\n",
    "        self.block1xc = ResidualPSA(tenmfeats, tenmfeats)\n",
    "                \n",
    "        # 2x -> 1x downsample skip connect (2xa - 1xb)\n",
    "        self.downsampleconva = nn.Conv2d(32, 32, 3, 2, 1, bias = False)\n",
    "        self.norm_layer_adown = nn.BatchNorm2d(32)\n",
    "        self.downsampleconv1x1a = nn.Conv2d(32+tenmfeats, tenmfeats, 1, bias = False)\n",
    "        self.norm_layer_adown2 = nn.BatchNorm2d(tenmfeats)\n",
    "        \n",
    "        # 2x -> 1x downsample skip connect (2xb - 1xc)\n",
    "        self.downsampleconvb = nn.Conv2d(32, 32, 3, 2, 1, bias = False)\n",
    "        self.norm_layer_bdown = nn.BatchNorm2d(32)\n",
    "        self.downsampleconv1x1b = nn.Conv2d(32+tenmfeats, tenmfeats, 1, bias = False)\n",
    "        self.norm_layer_bdown2 = nn.BatchNorm2d(tenmfeats)\n",
    "        \n",
    "        # 1x -> 2x upsample skip connect\n",
    "        #(1xa - 2xb)\n",
    "        self.upsample1x1conva = nn.Conv2d(32+tenmfeats, 32, 1, bias = False)\n",
    "        self.norm_layer_aup = nn.BatchNorm2d(32)\n",
    "        \n",
    "        #(1xb - 2xc)\n",
    "        self.upsample1x1convb = nn.Conv2d(32+tenmfeats, 32, 1, bias = False)\n",
    "        self.norm_layer_bup = nn.BatchNorm2d(32)\n",
    "        \n",
    "        #(1xc - 2xd)\n",
    "        self.upsample1x1convc = nn.Conv2d(32+tenmfeats, 32, 1, bias = False)\n",
    "        self.norm_layer_cup = nn.BatchNorm2d(32)\n",
    "        \n",
    "        # 2 - > 4\n",
    "        self.downsamplefeatsb = nn.Conv2d(32, 16, 1, 1, bias = True)\n",
    "        self.upsamplerb = CARAFE(16)\n",
    "        self.block4xa = ResidualPSA(16, 16)\n",
    "        self.upsample1x1convd = nn.Conv2d(32+16, 32, 1, bias = False)\n",
    "        self.norm_layer_dup = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.CFP_1 = CFPModule(32, d = 8)\n",
    "        self.CFP_2 = CFPModule(32, d = 8)\n",
    "        self.CFP_3 = CFPModule(32, d = 8)\n",
    "\n",
    "        self.ra1_conv1 = Conv(32, 32,3,1,padding=1,bn_acti=True)\n",
    "        self.ra1_conv3 = Conv(32,1,3,1,padding=1,bn_acti=True)\n",
    "        \n",
    "        self.ra2_conv1 = Conv(32,32,3,1,padding=1,bn_acti=True)\n",
    "        self.ra2_conv3 = Conv(32,1,3,1,padding=1,bn_acti=True)\n",
    "        \n",
    "        self.ra3_conv1 = Conv(32,32,3,1,padding=1,bn_acti=True)\n",
    "        self.ra3_conv3 = Conv(32,1,3,1,padding=1,bn_acti=True)\n",
    "        \n",
    "        self.aa_kernel_1 = AA_kernel(32, 32)\n",
    "        self.aa_kernel_2 = AA_kernel(32,32)\n",
    "        self.aa_kernel_3 = AA_kernel(32,32)\n",
    "\n",
    "\n",
    "        # Classifier\n",
    "        self.conv_last = nn.Conv2d(32, 1, 1, 1, bias = True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Residual PSA block the extracted features\n",
    "        fea1xa = self.block1xa(self.lrelu(self.feats(x)))\n",
    "        \n",
    "        # Upsample 1x -> 2x\n",
    "        # The output of this is attention features on the 5m feature extractions\n",
    "        fea2xa = self.upsampler(fea1xa)\n",
    "        fea2xa = self.PSA_p1(fea2xa)\n",
    "        \n",
    "        # B Blocks\n",
    "        # residual blocks on the 5-m and 10-m feats\n",
    "        fea2xb = self.block2xb(fea2xa)\n",
    "        fea1xb = self.block1xb(fea1xa)\n",
    "        \n",
    "        # C blocks\n",
    "        # (1xa -> 2xb)\n",
    "        # Cross-scale feature fusion\n",
    "        fea1xup = F.interpolate(fea1xb, scale_factor=2, mode='bilinear')\n",
    "        fea1xup = torch.concat([fea1xup, fea2xb], axis = 1)\n",
    "        fea1xupout_b = self.norm_layer_aup(self.upsample1x1conva(fea1xup))\n",
    "        # (2xa -> 1xb)\n",
    "        fea2xbdown = self.lrelu(self.norm_layer_adown(self.downsampleconva(fea2xb)))\n",
    "        fea2xbdown = torch.concat([fea2xbdown, fea1xb], axis = 1)\n",
    "        fea2xdownout_b = self.norm_layer_adown2(self.downsampleconv1x1a(fea2xbdown))\n",
    "        \n",
    "        fea2xc = self.block2xb(self.lrelu(fea1xupout_b))\n",
    "        fea1xc = self.block1xc(self.lrelu(fea2xdownout_b))\n",
    "    \n",
    "                               \n",
    "        # D blocks\n",
    "        # (1xb -> 2xc)\n",
    "        fea1xupc = F.interpolate(fea1xc, scale_factor=2, mode='bilinear')\n",
    "        fea1xupc = torch.concat([fea1xupc, fea2xc], axis = 1)\n",
    "        fea1xupout_c = self.norm_layer_cup(self.upsample1x1convc(fea1xupc))\n",
    "        \n",
    "        fea2xd = (self.lrelu(fea1xupout_c))#self.block2xd(self.lrelu(fea1xupout_c))\n",
    "        \n",
    "        # 2 - > 4\n",
    "        fea4xa = self.lrelu(self.downsamplefeatsb(fea2xd))\n",
    "        # Here we make 2.5 feats\n",
    "        fea4xa = self.upsamplerb(fea4xa)\n",
    "        fea4xa = self.PSA_p2(fea4xa)\n",
    "        fea4xa = self.block4xa(fea4xa)\n",
    "        fea4xup = F.interpolate(fea2xd, scale_factor=2, mode='bilinear')\n",
    "        fea4xa = torch.concat([fea4xa, fea4xup], axis = 1)\n",
    "        fea4xa = self.lrelu(self.norm_layer_dup(self.upsample1x1convd(fea4xa)))\n",
    "\n",
    "\n",
    "        # Axial attn\n",
    "        decoder_1 = self.conv_last(fea4xa)\n",
    "        \n",
    "        decoder_2 = F.interpolate(decoder_1, scale_factor=0.25, mode='bilinear')\n",
    "        cfp_out_1 = self.CFP_3(fea1xc) # 32 - 32\n",
    "        decoder_2_ra = -1*(torch.sigmoid(decoder_2)) + 1\n",
    "        aa_atten_3 = self.aa_kernel_3(cfp_out_1)\n",
    "        aa_atten_3_o = decoder_2_ra.expand(-1, 32, -1, -1).mul(aa_atten_3)\n",
    "        \n",
    "        \n",
    "        ra_3 = self.ra3_conv1(aa_atten_3_o) # 32 - 32\n",
    "        #ra_3 = self.ra3_conv2(ra_3) # 32 - 32\n",
    "        ra_3 = self.ra3_conv3(ra_3) # 32 - 1\n",
    "        x_3 = ra_3 + decoder_2 # 10m prediction here\n",
    "        #10m deep super\n",
    "        tenm_out = F.interpolate(x_3, scale_factor=4, mode='bilinear')\n",
    "        \n",
    "        decoder_3 = F.interpolate(x_3, scale_factor=2, mode='bilinear')\n",
    "        cfp_out_2 = self.CFP_2(fea2xc) # 32 - 32\n",
    "        decoder_3_ra = -1*(torch.sigmoid(decoder_3)) + 1\n",
    "        aa_atten_2 = self.aa_kernel_2(cfp_out_2)\n",
    "        aa_atten_2_o = decoder_3_ra.expand(-1, 32, -1, -1).mul(aa_atten_2)\n",
    "        \n",
    "        ra_2 = self.ra2_conv1(aa_atten_2_o) # 32 - 32\n",
    "        #ra_2 = self.ra2_conv2(ra_2) # 32 - 32\n",
    "        ra_2 = self.ra2_conv3(ra_2) # 32 - 1\n",
    "        \n",
    "        x_2 = ra_2 + decoder_3 # 5m prediction here\n",
    "        fivem_out = F.interpolate(x_2, scale_factor=2, mode='bilinear')\n",
    "        \n",
    "        decoder_4 = F.interpolate(x_2, scale_factor=2, mode='bilinear')\n",
    "        cfp_out_3 = self.CFP_1(fea4xa) # 32 - 32\n",
    "        decoder_4_ra = -1*(torch.sigmoid(decoder_4)) + 1\n",
    "        aa_atten_1 = self.aa_kernel_1(cfp_out_3)\n",
    "        aa_atten_1_o = decoder_4_ra.expand(-1, 32, -1, -1).mul(aa_atten_1)\n",
    "        \n",
    "        ra_1 = self.ra1_conv1(aa_atten_1_o) # 32 - 32\n",
    "        ra_1 = self.ra1_conv3(ra_1) # 32 - 1\n",
    "        \n",
    "        x_1 = ra_1 + decoder_4\n",
    "\n",
    "        out = x_1\n",
    "    \n",
    "        return out, decoder_1, tenm_out, fivem_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc546766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is where we actually make the model\n",
    "model = HRSupResNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfaff41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_params(model):\n",
    "    pp=0\n",
    "    for p in list(model.parameters()):\n",
    "        nn=1\n",
    "        for s in list(p.size()):\n",
    "            nn = nn*s\n",
    "        pp += nn\n",
    "    return pp\n",
    "\n",
    "print(get_n_params(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2931d9d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss() # Mean squared error between prediction and label\n",
    "\n",
    "# Set optimizers, learning rate scheduler\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "optimizer2 = torch.optim.SGD(model.parameters(), lr = 0.1, momentum = 0.9)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ef07d0",
   "metadata": {},
   "source": [
    "# Normalization #TODO - Gautam\n",
    "# CNN expects input to be centered around 0\n",
    "# You need to find the min, max per-band\n",
    "# And store it to pass to make_input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9ccb66",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "os.chdir(r\"C:\\Users\\Gautam.Mathur\\OneDrive - World Resources Institute\\Gautam Intern Materials\\All_Images_6\\resampled_results\")\n",
    "images = os.listdir()\n",
    "images = [i for i in images if i.endswith(\".tif\")]\n",
    "mins = []\n",
    "maxes = []\n",
    "\n",
    "for idx in range(5290):\n",
    "    try:\n",
    "        imgname = str(idx) + \"final.tif\"\n",
    "        img= rasterio.open(imgname).read().astype(np.float32)\n",
    "        maxval = []\n",
    "        minval = []\n",
    "        midr = []\n",
    "        for i in range(12):\n",
    "            m = np.max(img[i,...])\n",
    "            maxval.append(m)\n",
    "            n = np.min(img[i,...])\n",
    "            minval.append(n)\n",
    "        maxes.append(maxval)\n",
    "        mins.append(minval)\n",
    "        \n",
    "    except:\n",
    "        print(str(idx) + \" doesn't exist\")\n",
    "\n",
    "maxperband = []\n",
    "for i in range(12):\n",
    "    localmaxes = []\n",
    "    for j in maxes:\n",
    "        localmaxes.append(j[i])\n",
    "    maxperband.append(max(localmaxes))\n",
    "\n",
    "\n",
    "\n",
    "minperband = []\n",
    "for i in range(12):\n",
    "    localmins = []\n",
    "    for j in mins:\n",
    "        localmins.append(j[i])\n",
    "    minperband.append(max(localmins))\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "#midrange = (maxs[idx] + mins[idx]) / 2\n",
    "#rng = maxs[idx] - mins[idx]\n",
    "#arr[..., idx] = (arr[..., idx] - midrange[idx]) / (rng / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c53a3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input_data(files, maxes = maxperband, mins = minperband,\n",
    "                    batch_size = 8, size = 14, scale = 4, bandsin = 12, bandsout = 3):\n",
    "    \n",
    "    # Make the batch as an empty array\n",
    "    x_batch = np.zeros((batch_size, bandsin, size, size))\n",
    "    y_batch = np.zeros((batch_size, size*scale, size*scale, bandsout))\n",
    "    \n",
    "    # files should be a randomly selected list of batch_size files\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        imgfolder = r\"C:\\Users\\Gautam.Mathur\\All_Images_6\"\n",
    "        xpath = os.path.join(imgfolder, \"resampled_results\", str(files[i]) + \"final\"+  \".tif\")\n",
    "        ypath = os.path.join(imgfolder, \"wv\"+ str(files[i]) + \".tif\")\n",
    "        x_batch[i] = rasterio.open(xpath).read().astype(np.float32)\n",
    "        y_batch[i] = rasterio.open(ypath).read().astype(np.float32)\n",
    "\n",
    "    for idx in range(0, bandsin):\n",
    "        midrange = (maxes[idx] + mins[idx]) / 2\n",
    "        rng = maxes[idx] - mins[idx]\n",
    "        x_batch[idx, ...] = (x_batch[idx,...] - midrange) / (rng / 2)\n",
    "    return x_batch, y_batch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a67886",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, optimizer, path, name):\n",
    "    output_folder = f\"{path}{name}\"\n",
    "    if not os.path.exists(os.path.realpath(output_folder)):\n",
    "            os.makedirs(os.path.realpath(output_folder))\n",
    "    torch.save({\n",
    "            'epoch': name,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            }, f\"{output_folder}/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0436686",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def make_preds(logits):\n",
    "    logits = F.sigmoid(logits)\n",
    "    l_pred = torch.cat([1-logits, logits], axis = 1)\n",
    "    return l_pred\n",
    "#def batches(idxlist, outputlist, batch_size=8):\n",
    "        #if len(idxlist)>=batch_size:\n",
    "            #random.shuffle(idxlist)\n",
    "            #batch = idxlist[:batch_size]\n",
    "            #outputlist.append(batch)\n",
    "            #idxlist=idxlist[batch_size:]\n",
    "            #batches(idxlist, outputlist)\n",
    "\n",
    "#model = torch.load('models/supres/HRNet_5m_400/model')\n",
    "model.train()\n",
    "for epoch in range(1, 200):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "\n",
    "    scale = 4\n",
    "    size = 28\n",
    "    \n",
    "    # Write a function here to make a list of batchnames\n",
    "    batchnames = []\n",
    "    train_samples = np.arange(0, 5290)\n",
    "    random.shuffle(train_samples)\n",
    "    batch_size = 8\n",
    "    for batch in np.arange(0, len(train_samples), batch_size):\n",
    "        batch_samples = train_samples[batch:batch + batch_size]\n",
    "        batchnames.append(batch_samples)\n",
    "    \n",
    "\n",
    "    #batches()\n",
    "    for batch in batchnames: #iterate through the length of training data divided by batch size\n",
    "        \n",
    "        inputs, labels, = make_input_data(batch,  \n",
    "                                           batch_size = 8, \n",
    "                                           size = size,\n",
    "                                           scale = scale)\n",
    "        \n",
    "\n",
    "        inputs = torch.tensor(inputs).float()\n",
    "        labels = torch.tensor(labels).float()\n",
    "\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs, tenm_out, fivem_out = model.float()(inputs)\n",
    "\n",
    "        outputs = make_preds(outputs)\n",
    "        fivem_out = make_preds(fivem_out)\n",
    "        tenm_out = make_preds(tenm_out)\n",
    "\n",
    "        labs = torch.cat([1 - labels[:, np.newaxis, ...], \n",
    "                                             labels[:, np.newaxis, ...]], axis = 1)\n",
    "  \n",
    "    \n",
    "        loss =  criterion(outputs, labs)\n",
    "        loss_5m = criterion(fivem_out, labs)\n",
    "        loss_tenm = criterion(tenm_out, labs)\n",
    "\n",
    "        loss = (loss + loss_5m + loss_tenm) / 3\n",
    "\n",
    "        \n",
    "        if not torch.isnan(loss):\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        else:\n",
    "            print(\"nan loss\")\n",
    "            \n",
    "    if epoch % 2 == 0:\n",
    "        save_model(model, optimizer,\n",
    "                   path = 'models/supres/folder_name', # Make a folder name\n",
    "                   name = str(epoch).zfill(3))\n",
    "\n",
    "    print(f'[{epoch + 1}] loss: {loss.item()}')\n",
    "    running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "#torch.save(model, \"models/supres/HRNet_5m_1000_carafe_PSA_backbone_gru/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe746860",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, optimizer,\n",
    "                   path = 'models/supres/HRNet_4x_carafe_master-',\n",
    "                   name = str(epoch).zfill(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8481f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('models/supres/HRNet_4x_carafe_master-559/model')\n",
    "\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966cea30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#INPUT\n",
    "#- resamples result from coregistration (10 m, all 10 bands)\n",
    "#- resampled 2.5 m WVimage\n",
    "\n",
    "#-model iteratively gets trained on random samples of size 8, 16, or 32\n",
    "#- output should be scaled from 0 to 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
